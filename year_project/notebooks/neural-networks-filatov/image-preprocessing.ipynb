{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57aed000",
   "metadata": {
    "papermill": {
     "duration": 0.00297,
     "end_time": "2024-05-18T10:25:17.937836",
     "exception": false,
     "start_time": "2024-05-18T10:25:17.934866",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Предобработка изображений из `train` и `test` датасетов\n",
    "\n",
    "**Цель:** \n",
    "\n",
    "1. _Аугментации_, так как для каждого класса их нужно разное количество `augs_need`\n",
    "\n",
    "2. Изменение файловой структуры датасетов для удобного использования в `torch.Dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07a3911d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-18T10:25:17.945534Z",
     "iopub.status.busy": "2024-05-18T10:25:17.944807Z",
     "iopub.status.idle": "2024-05-18T10:25:28.507938Z",
     "shell.execute_reply": "2024-05-18T10:25:28.506827Z"
    },
    "papermill": {
     "duration": 10.570167,
     "end_time": "2024-05-18T10:25:28.510651",
     "exception": false,
     "start_time": "2024-05-18T10:25:17.940484",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import albumentations as A\n",
    "\n",
    "from scipy.stats import bernoulli\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123e415a",
   "metadata": {
    "papermill": {
     "duration": 0.002191,
     "end_time": "2024-05-18T10:25:28.515575",
     "exception": false,
     "start_time": "2024-05-18T10:25:28.513384",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Функция для загрузки и предобработки изображений**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "622b3f12",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-18T10:25:28.522882Z",
     "iopub.status.busy": "2024-05-18T10:25:28.522012Z",
     "iopub.status.idle": "2024-05-18T10:39:13.497546Z",
     "shell.execute_reply": "2024-05-18T10:39:13.496163Z"
    },
    "papermill": {
     "duration": 824.982689,
     "end_time": "2024-05-18T10:39:13.500618",
     "exception": false,
     "start_time": "2024-05-18T10:25:28.517929",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# во сколько раз больше нужно объектов каждого класса для устранения дисбаланса классов\n",
    "augs_need = np.array([2.47359155, 3.3452381 , 1.67261905, 2.31848185, 5.40384615,\n",
    "                      2.91493776, 6.62735849, 2.87321063, 3.13616071, 5.87866109,\n",
    "                      1.08076923, 1.        , 3.03455724, 1.35096154, 3.25986079,\n",
    "                      1.13765182, 3.47772277, 3.4691358 , 1.02479942, 1.22280244,\n",
    "                      3.37740385, 4.87847222, 1.29373849])\n",
    "\n",
    "\n",
    "def load_images(data='train'):\n",
    "    path = f\"../input/dermnet/{data}/\"\n",
    "    list_cat = os.listdir(path)\n",
    "    \n",
    "    os.mkdir(f'{data}')\n",
    "    os.mkdir(f'{data}/images')\n",
    "    \n",
    "    augmentation = A.Compose([\n",
    "        A.Rotate(limit=180, border_mode=4, p=1.0),\n",
    "        A.GaussNoise(var_limit=(20, 40), p=0.5), \n",
    "        A.RandomBrightnessContrast(brightness_limit=0.15, contrast_limit=0.15, p=0.5)\n",
    "    ])\n",
    "    \n",
    "    idx = 0\n",
    "    labels = torch.zeros(33000)\n",
    "    for i, cat in enumerate(list_cat):      \n",
    "        list_images = os.listdir(path + cat)\n",
    "        aug_count = augs_need[i]\n",
    "\n",
    "        for j in list_images:   \n",
    "            with Image.open(path + cat + \"/\" + j) as input_image:\n",
    "                for p in range(int(aug_count) + bernoulli.rvs(aug_count - int(aug_count))): \n",
    "                    # применяем аугментации\n",
    "                    if p:\n",
    "                        input_image = Image.fromarray(augmentation(image=np.array(input_image))[\"image\"])\n",
    "                    \n",
    "                    # сохраняем изображения в новые директории\n",
    "                    input_image.save(f'{data}/images/image({idx}).jpg')    \n",
    "                    \n",
    "                    # записываем лейблы в тензор\n",
    "                    labels[idx] = i\n",
    "\n",
    "                    # счётчик общего количества добавленных изображений\n",
    "                    idx += 1\n",
    "                    \n",
    "                    if data == 'test':  # для теста аугментации не нужны\n",
    "                        break\n",
    "\n",
    "    labels.resize_(idx)\n",
    "    torch.save(labels, f'{data}/labels.pt')\n",
    "    \n",
    "\n",
    "# загружаем датасеты\n",
    "load_images('train')\n",
    "load_images('test')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 735911,
     "sourceId": 1276317,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30684,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 840.723588,
   "end_time": "2024-05-18T10:39:15.131985",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-05-18T10:25:14.408397",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
